"use strict";(self.webpackChunkdiscoverse_docs=self.webpackChunkdiscoverse_docs||[]).push([[9238],{4607:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"tutorials/imitation-learning/overview","title":"Imitation Learning Overview","description":"DISCOVERSE provides a complete imitation learning workflow, supporting end-to-end training from data collection to policy deployment. This chapter introduces four mainstream imitation learning algorithms integrated in the framework.","source":"@site/docs/tutorials/imitation-learning/overview.md","sourceDirName":"tutorials/imitation-learning","slug":"/tutorials/imitation-learning/overview","permalink":"/DISCOVERSE-doc/docs/tutorials/imitation-learning/overview","draft":false,"unlisted":false,"editUrl":"https://github.com/TATP-233/DISCOVERSE/tree/main/discoverse-docs/docs/tutorials/imitation-learning/overview.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Stereo Camera Simulation Details","permalink":"/DISCOVERSE-doc/docs/tutorials/sensors/stereo-camera"},"next":{"title":"Data Generation","permalink":"/DISCOVERSE-doc/docs/tutorials/imitation-learning/data-generation"}}');var t=i(4848),o=i(8453);const s={sidebar_position:1},a="Imitation Learning Overview",l={},c=[{value:"\ud83c\udfaf Supported Algorithms",id:"-supported-algorithms",level:2},{value:"1. <strong>ACT</strong> (Action Chunking with Transformers)",id:"1-act-action-chunking-with-transformers",level:3},{value:"2. <strong>DP</strong> (Diffusion Policy)",id:"2-dp-diffusion-policy",level:3},{value:"3. <strong>RDT</strong> (Robotics Diffusion Transformer)",id:"3-rdt-robotics-diffusion-transformer",level:3},{value:"4. <strong>OpenPI</strong> (Open-source Policy Interface)",id:"4-openpi-open-source-policy-interface",level:3},{value:"\ud83d\udd04 Workflow",id:"-workflow",level:2},{value:"1. Data Generation",id:"1-data-generation",level:3},{value:"2. Data Format Conversion",id:"2-data-format-conversion",level:3}];function d(n){const e={h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"imitation-learning-overview",children:"Imitation Learning Overview"})}),"\n",(0,t.jsx)(e.p,{children:"DISCOVERSE provides a complete imitation learning workflow, supporting end-to-end training from data collection to policy deployment. This chapter introduces four mainstream imitation learning algorithms integrated in the framework."}),"\n",(0,t.jsx)(e.h2,{id:"-supported-algorithms",children:"\ud83c\udfaf Supported Algorithms"}),"\n",(0,t.jsx)(e.p,{children:"Currently, DISCOVERSE supports the following four imitation learning algorithms:"}),"\n",(0,t.jsxs)(e.h3,{id:"1-act-action-chunking-with-transformers",children:["1. ",(0,t.jsx)(e.strong,{children:"ACT"})," (Action Chunking with Transformers)"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Data format"}),": HDF5"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Use case"}),": Complex manipulation tasks requiring long sequence planning"]}),"\n"]}),"\n",(0,t.jsxs)(e.h3,{id:"2-dp-diffusion-policy",children:["2. ",(0,t.jsx)(e.strong,{children:"DP"})," (Diffusion Policy)"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Data format"}),": Zarr"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Use case"}),": Multimodal action distributions, complex manipulation skills"]}),"\n"]}),"\n",(0,t.jsxs)(e.h3,{id:"3-rdt-robotics-diffusion-transformer",children:["3. ",(0,t.jsx)(e.strong,{children:"RDT"})," (Robotics Diffusion Transformer)"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Data format"}),": HDF5"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Use case"}),": Multi-task learning, general robot skills"]}),"\n"]}),"\n",(0,t.jsxs)(e.h3,{id:"4-openpi-open-source-policy-interface",children:["4. ",(0,t.jsx)(e.strong,{children:"OpenPI"})," (Open-source Policy Interface)"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Data format"}),": HDF5"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Use case"}),": Rapid prototyping, few-shot learning"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"-workflow",children:"\ud83d\udd04 Workflow"}),"\n",(0,t.jsx)(e.p,{children:"The complete imitation learning workflow includes the following steps:"}),"\n",(0,t.jsx)(e.h3,{id:"1-data-generation",children:"1. Data Generation"}),"\n",(0,t.jsx)(e.p,{children:"Automatically generate demonstration data, 100x more efficient than the real world"}),"\n",(0,t.jsx)(e.h3,{id:"2-data-format-conversion",children:"2. Data Format Conversion"}),"\n",(0,t.jsx)(e.p,{children:"Convert to the required format for each algorithm:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"ACT/RDT/OpenPI"}),": Raw data \ufffd?HDF5"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"DP"}),": Raw data \ufffd?Zarr"]}),"\n"]})]})}function h(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>s,x:()=>a});var r=i(6540);const t={},o=r.createContext(t);function s(n){const e=r.useContext(o);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:s(n.components),r.createElement(o.Provider,{value:e},n.children)}}}]);