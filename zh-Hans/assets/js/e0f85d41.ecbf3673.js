"use strict";(self.webpackChunkdiscoverse_docs=self.webpackChunkdiscoverse_docs||[]).push([[8112],{8453:(n,e,r)=>{r.d(e,{R:()=>i,x:()=>a});var t=r(6540);const o={},s=t.createContext(o);function i(n){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:i(n.components),t.createElement(s.Provider,{value:e},n.children)}},9663:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>i,metadata:()=>t,toc:()=>p});const t=JSON.parse('{"id":"tutorials/basic-simulation/robot-control","title":"\u673a\u5668\u4eba\u63a7\u5236","description":"\u672c\u6559\u7a0b\u5c06\u6df1\u5165\u4ecb\u7ecdDISCOVERSE\u4e2d\u7684\u673a\u5668\u4eba\u63a7\u5236\u7cfb\u7edf\uff0c\u5305\u62ec\u4e0d\u540c\u7684\u63a7\u5236\u6a21\u5f0f\u3001\u8fd0\u52a8\u5b66\u8ba1\u7b97\u3001\u8f68\u8ff9\u89c4\u5212\u548c\u5b9e\u65f6\u63a7\u5236\u3002","source":"@site/i18n/zh-Hans/docusaurus-plugin-content-docs/current/tutorials/basic-simulation/robot-control.md","sourceDirName":"tutorials/basic-simulation","slug":"/tutorials/basic-simulation/robot-control","permalink":"/zh-Hans/docs/tutorials/basic-simulation/robot-control","draft":false,"unlisted":false,"editUrl":"https://github.com/TATP-233/DISCOVERSE/tree/main/discoverse-docs/docs/tutorials/basic-simulation/robot-control.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"\u57fa\u7840\u4eff\u771f\u6982\u89c8","permalink":"/zh-Hans/docs/tutorials/basic-simulation/overview"},"next":{"title":"\u7acb\u4f53\u76f8\u673a\u4eff\u771f\u8be6\u89e3","permalink":"/zh-Hans/docs/tutorials/sensors/stereo-camera"}}');var o=r(4848),s=r(8453);const i={},a="\u673a\u5668\u4eba\u63a7\u5236",l={},p=[{value:"\ud83c\udfaf \u5b66\u4e60\u76ee\u6807",id:"-\u5b66\u4e60\u76ee\u6807",level:2},{value:"\ud83c\udfae \u63a7\u5236\u6a21\u5f0f\u8be6\u89e3",id:"-\u63a7\u5236\u6a21\u5f0f\u8be6\u89e3",level:2},{value:"1. \u5173\u8282\u4f4d\u7f6e\u63a7\u5236 (pd_joint_pos)",id:"1-\u5173\u8282\u4f4d\u7f6e\u63a7\u5236-pd_joint_pos",level:3},{value:"2. \u5173\u8282\u589e\u91cf\u63a7\u5236 (pd_joint_delta_pos)",id:"2-\u5173\u8282\u589e\u91cf\u63a7\u5236-pd_joint_delta_pos",level:3},{value:"3. \u672b\u7aef\u6267\u884c\u5668\u63a7\u5236 (pd_ee_pose)",id:"3-\u672b\u7aef\u6267\u884c\u5668\u63a7\u5236-pd_ee_pose",level:3},{value:"4. \u901f\u5ea6\u63a7\u5236 (pd_joint_vel)",id:"4-\u901f\u5ea6\u63a7\u5236-pd_joint_vel",level:3},{value:"\ud83d\udd27 \u8fd0\u52a8\u5b66\u8ba1\u7b97",id:"-\u8fd0\u52a8\u5b66\u8ba1\u7b97",level:2},{value:"\u6b63\u5411\u8fd0\u52a8\u5b66 (Forward Kinematics)",id:"\u6b63\u5411\u8fd0\u52a8\u5b66-forward-kinematics",level:3},{value:"\u53cd\u5411\u8fd0\u52a8\u5b66 (Inverse Kinematics)",id:"\u53cd\u5411\u8fd0\u52a8\u5b66-inverse-kinematics",level:3},{value:"\u591a\u89e3\u5904\u7406",id:"\u591a\u89e3\u5904\u7406",level:3},{value:"\ud83d\udcc8 \u8f68\u8ff9\u89c4\u5212",id:"-\u8f68\u8ff9\u89c4\u5212",level:2},{value:"\u5173\u8282\u7a7a\u95f4\u8f68\u8ff9",id:"\u5173\u8282\u7a7a\u95f4\u8f68\u8ff9",level:3},{value:"\u7b1b\u5361\u5c14\u7a7a\u95f4\u8f68\u8ff9",id:"\u7b1b\u5361\u5c14\u7a7a\u95f4\u8f68\u8ff9",level:3},{value:"\ud83c\udfaf \u9ad8\u7ea7\u63a7\u5236\u6280\u672f",id:"-\u9ad8\u7ea7\u63a7\u5236\u6280\u672f",level:2},{value:"\u963b\u6297\u63a7\u5236",id:"\u963b\u6297\u63a7\u5236",level:3},{value:"\u529b\u63a7\u5236",id:"\u529b\u63a7\u5236",level:3},{value:"\ud83d\udd04 \u63a7\u5236\u5faa\u73af\u4f18\u5316",id:"-\u63a7\u5236\u5faa\u73af\u4f18\u5316",level:2},{value:"PID\u53c2\u6570\u8c03\u4f18",id:"pid\u53c2\u6570\u8c03\u4f18",level:3},{value:"\u5b89\u5168\u9650\u5236",id:"\u5b89\u5168\u9650\u5236",level:3},{value:"\ud83d\udcca \u63a7\u5236\u6027\u80fd\u8bc4\u4f30",id:"-\u63a7\u5236\u6027\u80fd\u8bc4\u4f30",level:2},{value:"\u8f68\u8ff9\u8ddf\u8e2a\u7cbe\u5ea6",id:"\u8f68\u8ff9\u8ddf\u8e2a\u7cbe\u5ea6",level:3},{value:"\ud83c\udfaf \u5b9e\u9645\u5e94\u7528\u793a\u4f8b",id:"-\u5b9e\u9645\u5e94\u7528\u793a\u4f8b",level:2},{value:"\u62fe\u53d6\u7269\u4f53\u4efb\u52a1",id:"\u62fe\u53d6\u7269\u4f53\u4efb\u52a1",level:3},{value:"\ud83c\udfaf \u4e0b\u4e00\u6b65",id:"-\u4e0b\u4e00\u6b65",level:2}];function c(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"\u673a\u5668\u4eba\u63a7\u5236",children:"\u673a\u5668\u4eba\u63a7\u5236"})}),"\n",(0,o.jsx)(e.p,{children:"\u672c\u6559\u7a0b\u5c06\u6df1\u5165\u4ecb\u7ecdDISCOVERSE\u4e2d\u7684\u673a\u5668\u4eba\u63a7\u5236\u7cfb\u7edf\uff0c\u5305\u62ec\u4e0d\u540c\u7684\u63a7\u5236\u6a21\u5f0f\u3001\u8fd0\u52a8\u5b66\u8ba1\u7b97\u3001\u8f68\u8ff9\u89c4\u5212\u548c\u5b9e\u65f6\u63a7\u5236\u3002"}),"\n",(0,o.jsx)(e.h2,{id:"-\u5b66\u4e60\u76ee\u6807",children:"\ud83c\udfaf \u5b66\u4e60\u76ee\u6807"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"\u638c\u63e1DISCOVERSE\u7684\u6240\u6709\u63a7\u5236\u6a21\u5f0f"}),"\n",(0,o.jsx)(e.li,{children:"\u7406\u89e3\u6b63\u5411\u548c\u53cd\u5411\u8fd0\u52a8\u5b66"}),"\n",(0,o.jsx)(e.li,{children:"\u5b66\u4e60\u8f68\u8ff9\u89c4\u5212\u548c\u5e73\u6ed1\u63a7\u5236"}),"\n",(0,o.jsx)(e.li,{children:"\u5b9e\u73b0\u590d\u6742\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"-\u63a7\u5236\u6a21\u5f0f\u8be6\u89e3",children:"\ud83c\udfae \u63a7\u5236\u6a21\u5f0f\u8be6\u89e3"}),"\n",(0,o.jsx)(e.h3,{id:"1-\u5173\u8282\u4f4d\u7f6e\u63a7\u5236-pd_joint_pos",children:"1. \u5173\u8282\u4f4d\u7f6e\u63a7\u5236 (pd_joint_pos)"}),"\n",(0,o.jsx)(e.p,{children:"\u6700\u57fa\u7840\u7684\u63a7\u5236\u6a21\u5f0f\uff0c\u76f4\u63a5\u6307\u5b9a\u76ee\u6807\u5173\u8282\u89d2\u5ea6\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import discoverse as dv\nimport numpy as np\n\nenv = dv.make_env("airbot_play", control_mode="pd_joint_pos")\nobs = env.reset()\n\n# \u83b7\u53d6\u5f53\u524d\u5173\u8282\u4f4d\u7f6e\ncurrent_qpos = obs["qpos"]  # \u5f53\u524d\u5173\u8282\u89d2\u5ea6\nprint(f"\u5f53\u524d\u5173\u8282\u4f4d\u7f6e: {current_qpos}")\n\n# \u8bbe\u7f6e\u76ee\u6807\u5173\u8282\u4f4d\u7f6e\ntarget_qpos = np.array([0.0, -0.5, 0.0, 1.57, 0.0, 1.0, 0.0])\n\n# \u6267\u884c\u63a7\u5236\nobs, reward, done, info = env.step(target_qpos)\nenv.render()\n'})}),"\n",(0,o.jsx)(e.h3,{id:"2-\u5173\u8282\u589e\u91cf\u63a7\u5236-pd_joint_delta_pos",children:"2. \u5173\u8282\u589e\u91cf\u63a7\u5236 (pd_joint_delta_pos)"}),"\n",(0,o.jsx)(e.p,{children:"\u901a\u8fc7\u589e\u91cf\u65b9\u5f0f\u63a7\u5236\u5173\u8282\uff0c\u9002\u5408\u7cbe\u7ec6\u64cd\u4f5c\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'env = dv.make_env("airbot_play", control_mode="pd_joint_delta_pos")\nobs = env.reset()\n\n# \u5e73\u6ed1\u79fb\u52a8\u5230\u76ee\u6807\u4f4d\u7f6e\ntarget = np.array([0.0, -0.5, 0.0, 1.57, 0.0, 1.0, 0.0])\ncurrent = obs["qpos"]\n\nfor step in range(100):\n    # \u8ba1\u7b97\u589e\u91cf\n    delta = (target - current) * 0.1  # 10%\u7684\u6b65\u957f\n    \n    # \u6267\u884c\u589e\u91cf\u63a7\u5236\n    obs, reward, done, info = env.step(delta)\n    current = obs["qpos"]\n    \n    # \u68c0\u67e5\u662f\u5426\u5230\u8fbe\u76ee\u6807\n    if np.linalg.norm(target - current) < 0.01:\n        print(f"\u5728\u7b2c{step}\u6b65\u5230\u8fbe\u76ee\u6807")\n        break\n    \n    env.render()\n'})}),"\n",(0,o.jsx)(e.h3,{id:"3-\u672b\u7aef\u6267\u884c\u5668\u63a7\u5236-pd_ee_pose",children:"3. \u672b\u7aef\u6267\u884c\u5668\u63a7\u5236 (pd_ee_pose)"}),"\n",(0,o.jsx)(e.p,{children:"\u76f4\u63a5\u63a7\u5236\u673a\u5668\u4eba\u672b\u7aef\u6267\u884c\u5668\u7684\u4f4d\u59ff\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'env = dv.make_env("airbot_play", control_mode="pd_ee_pose")\nobs = env.reset()\n\n# \u83b7\u53d6\u5f53\u524d\u672b\u7aef\u6267\u884c\u5668\u4f4d\u59ff\ncurrent_ee_pose = obs["ee_pose"]  # [x, y, z, qx, qy, qz, qw]\nprint(f"\u5f53\u524d\u672b\u7aef\u4f4d\u59ff: {current_ee_pose}")\n\n# \u8bbe\u7f6e\u76ee\u6807\u4f4d\u59ff (\u4f4d\u7f6e + \u56db\u5143\u6570)\ntarget_position = [0.5, 0.2, 0.3]  # x, y, z\ntarget_quaternion = [0.0, 0.0, 0.0, 1.0]  # qx, qy, qz, qw (\u65e0\u65cb\u8f6c)\ntarget_pose = target_position + target_quaternion\n\n# \u6267\u884c\u63a7\u5236\nobs, reward, done, info = env.step(target_pose)\nenv.render()\n'})}),"\n",(0,o.jsx)(e.h3,{id:"4-\u901f\u5ea6\u63a7\u5236-pd_joint_vel",children:"4. \u901f\u5ea6\u63a7\u5236 (pd_joint_vel)"}),"\n",(0,o.jsx)(e.p,{children:"\u63a7\u5236\u5173\u8282\u901f\u5ea6\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'env = dv.make_env("airbot_play", control_mode="pd_joint_vel")\nobs = env.reset()\n\n# \u8bbe\u7f6e\u5173\u8282\u901f\u5ea6 (rad/s)\njoint_velocities = np.array([0.1, -0.2, 0.0, 0.3, 0.0, -0.1, 0.0])\n\nfor step in range(100):\n    obs, reward, done, info = env.step(joint_velocities)\n    \n    # \u53ef\u4ee5\u52a8\u6001\u8c03\u6574\u901f\u5ea6\n    if step == 50:\n        joint_velocities *= -1  # \u53cd\u5411\u8fd0\u52a8\n    \n    env.render()\n'})}),"\n",(0,o.jsx)(e.h2,{id:"-\u8fd0\u52a8\u5b66\u8ba1\u7b97",children:"\ud83d\udd27 \u8fd0\u52a8\u5b66\u8ba1\u7b97"}),"\n",(0,o.jsx)(e.h3,{id:"\u6b63\u5411\u8fd0\u52a8\u5b66-forward-kinematics",children:"\u6b63\u5411\u8fd0\u52a8\u5b66 (Forward Kinematics)"}),"\n",(0,o.jsx)(e.p,{children:"\u4ece\u5173\u8282\u89d2\u5ea6\u8ba1\u7b97\u672b\u7aef\u6267\u884c\u5668\u4f4d\u59ff\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import discoverse as dv\n\nenv = dv.make_env("airbot_play")\nrobot = env.robot  # \u83b7\u53d6\u673a\u5668\u4eba\u5bf9\u8c61\n\n# \u7ed9\u5b9a\u5173\u8282\u89d2\u5ea6\njoint_angles = np.array([0.0, -0.5, 0.0, 1.57, 0.0, 1.0, 0.0])\n\n# \u8ba1\u7b97\u6b63\u5411\u8fd0\u52a8\u5b66\nee_pose = robot.forward_kinematics(joint_angles)\nprint(f"\u672b\u7aef\u4f4d\u7f6e: {ee_pose[:3]}")\nprint(f"\u672b\u7aef\u65b9\u5411 (\u56db\u5143\u6570): {ee_pose[3:]}")\n\n# \u4e5f\u53ef\u4ee5\u8ba1\u7b97\u96c5\u53ef\u6bd4\u77e9\u9635\njacobian = robot.compute_jacobian(joint_angles)\nprint(f"\u96c5\u53ef\u6bd4\u77e9\u9635\u5f62\u72b6: {jacobian.shape}")  # (6, 7) for 7-DOF arm\n'})}),"\n",(0,o.jsx)(e.h3,{id:"\u53cd\u5411\u8fd0\u52a8\u5b66-inverse-kinematics",children:"\u53cd\u5411\u8fd0\u52a8\u5b66 (Inverse Kinematics)"}),"\n",(0,o.jsx)(e.p,{children:"\u4ece\u76ee\u6807\u672b\u7aef\u4f4d\u59ff\u8ba1\u7b97\u5173\u8282\u89d2\u5ea6\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# \u76ee\u6807\u672b\u7aef\u4f4d\u59ff\ntarget_position = [0.5, 0.0, 0.3]\ntarget_orientation = [0.0, 0.0, 0.0, 1.0]  # \u56db\u5143\u6570\ntarget_pose = np.array(target_position + target_orientation)\n\n# \u8ba1\u7b97\u53cd\u5411\u8fd0\u52a8\u5b66\nik_solution = robot.inverse_kinematics(\n    target_pose,\n    initial_guess=joint_angles,  # \u521d\u59cb\u731c\u6d4b\n    tolerance=1e-4,              # \u6c42\u89e3\u7cbe\u5ea6\n    max_iterations=100           # \u6700\u5927\u8fed\u4ee3\u6b21\u6570\n)\n\nif ik_solution is not None:\n    print(f"IK\u89e3: {ik_solution}")\n    \n    # \u9a8c\u8bc1\u89e3\u7684\u6b63\u786e\u6027\n    computed_pose = robot.forward_kinematics(ik_solution)\n    error = np.linalg.norm(computed_pose - target_pose)\n    print(f"\u4f4d\u59ff\u8bef\u5dee: {error:.6f}")\nelse:\n    print("\u672a\u627e\u5230IK\u89e3")\n'})}),"\n",(0,o.jsx)(e.h3,{id:"\u591a\u89e3\u5904\u7406",children:"\u591a\u89e3\u5904\u7406"}),"\n",(0,o.jsx)(e.p,{children:"IK\u95ee\u9898\u53ef\u80fd\u6709\u591a\u4e2a\u89e3\uff0cDISCOVERSE\u63d0\u4f9b\u4e86\u5904\u7406\u65b9\u6cd5\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# \u83b7\u53d6\u6240\u6709\u53ef\u80fd\u7684IK\u89e3\nall_solutions = robot.inverse_kinematics_all(\n    target_pose,\n    tolerance=1e-4\n)\n\nprint(f"\u627e\u5230 {len(all_solutions)} \u4e2a\u89e3")\n\n# \u9009\u62e9\u6700\u63a5\u8fd1\u5f53\u524d\u5173\u8282\u89d2\u5ea6\u7684\u89e3\ncurrent_angles = obs["qpos"]\nbest_solution = None\nmin_distance = float(\'inf\')\n\nfor solution in all_solutions:\n    distance = np.linalg.norm(solution - current_angles)\n    if distance < min_distance:\n        min_distance = distance\n        best_solution = solution\n\nprint(f"\u6700\u4f18\u89e3: {best_solution}")\n'})}),"\n",(0,o.jsx)(e.h2,{id:"-\u8f68\u8ff9\u89c4\u5212",children:"\ud83d\udcc8 \u8f68\u8ff9\u89c4\u5212"}),"\n",(0,o.jsx)(e.h3,{id:"\u5173\u8282\u7a7a\u95f4\u8f68\u8ff9",children:"\u5173\u8282\u7a7a\u95f4\u8f68\u8ff9"}),"\n",(0,o.jsx)(e.p,{children:"\u5728\u5173\u8282\u7a7a\u95f4\u4e2d\u89c4\u5212\u5e73\u6ed1\u8f68\u8ff9\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def plan_joint_trajectory(start_angles, end_angles, duration, freq=50):\n    """\u89c4\u5212\u5173\u8282\u7a7a\u95f4\u8f68\u8ff9"""\n    num_steps = int(duration * freq)\n    trajectory = []\n    \n    for i in range(num_steps + 1):\n        t = i / num_steps\n        # \u4f7f\u7528\u4e09\u6b21\u591a\u9879\u5f0f\u63d2\u503c\n        s = 3 * t**2 - 2 * t**3  # S\u66f2\u7ebf\n        angles = start_angles + s * (end_angles - start_angles)\n        trajectory.append(angles)\n    \n    return np.array(trajectory)\n\n# \u89c4\u5212\u8f68\u8ff9\nstart = obs["qpos"]\ngoal = np.array([0.0, -0.5, 0.0, 1.57, 0.0, 1.0, 0.0])\ntrajectory = plan_joint_trajectory(start, goal, duration=3.0)\n\n# \u6267\u884c\u8f68\u8ff9\nenv = dv.make_env("airbot_play", control_mode="pd_joint_pos")\nobs = env.reset()\n\nfor waypoint in trajectory:\n    obs, reward, done, info = env.step(waypoint)\n    env.render()\n    \n    if done:\n        break\n'})}),"\n",(0,o.jsx)(e.h3,{id:"\u7b1b\u5361\u5c14\u7a7a\u95f4\u8f68\u8ff9",children:"\u7b1b\u5361\u5c14\u7a7a\u95f4\u8f68\u8ff9"}),"\n",(0,o.jsx)(e.p,{children:"\u5728\u7b1b\u5361\u5c14\u7a7a\u95f4\u4e2d\u89c4\u5212\u76f4\u7ebf\u8f68\u8ff9\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def plan_cartesian_trajectory(start_pose, end_pose, duration, freq=50):\n    """\u89c4\u5212\u7b1b\u5361\u5c14\u7a7a\u95f4\u76f4\u7ebf\u8f68\u8ff9"""\n    num_steps = int(duration * freq)\n    trajectory = []\n    \n    start_pos, start_quat = start_pose[:3], start_pose[3:]\n    end_pos, end_quat = end_pose[:3], end_pose[3:]\n    \n    for i in range(num_steps + 1):\n        t = i / num_steps\n        \n        # \u4f4d\u7f6e\u7ebf\u6027\u63d2\u503c\n        pos = start_pos + t * (end_pos - start_pos)\n        \n        # \u56db\u5143\u6570\u7403\u9762\u7ebf\u6027\u63d2\u503c (SLERP)\n        quat = slerp(start_quat, end_quat, t)\n        \n        pose = np.concatenate([pos, quat])\n        trajectory.append(pose)\n    \n    return np.array(trajectory)\n\ndef slerp(q1, q2, t):\n    """\u56db\u5143\u6570\u7403\u9762\u7ebf\u6027\u63d2\u503c"""\n    q1, q2 = np.array(q1), np.array(q2)\n    \n    # \u786e\u4fdd\u9009\u62e9\u6700\u77ed\u8def\u5f84\n    if np.dot(q1, q2) < 0:\n        q2 = -q2\n    \n    dot = np.clip(np.dot(q1, q2), -1.0, 1.0)\n    omega = np.arccos(np.abs(dot))\n    \n    if np.sin(omega) < 1e-6:\n        return q1  # \u56db\u5143\u6570\u51e0\u4e4e\u76f8\u540c\n    \n    return (np.sin((1-t)*omega) * q1 + np.sin(t*omega) * q2) / np.sin(omega)\n\n# \u6267\u884c\u7b1b\u5361\u5c14\u8f68\u8ff9\nenv = dv.make_env("airbot_play", control_mode="pd_ee_pose")\nobs = env.reset()\n\nstart_pose = obs["ee_pose"]\nend_pose = np.array([0.5, 0.2, 0.4, 0.0, 0.0, 0.0, 1.0])\ncart_trajectory = plan_cartesian_trajectory(start_pose, end_pose, duration=2.0)\n\nfor waypoint in cart_trajectory:\n    obs, reward, done, info = env.step(waypoint)\n    env.render()\n'})}),"\n",(0,o.jsx)(e.h2,{id:"-\u9ad8\u7ea7\u63a7\u5236\u6280\u672f",children:"\ud83c\udfaf \u9ad8\u7ea7\u63a7\u5236\u6280\u672f"}),"\n",(0,o.jsx)(e.h3,{id:"\u963b\u6297\u63a7\u5236",children:"\u963b\u6297\u63a7\u5236"}),"\n",(0,o.jsx)(e.p,{children:"\u5b9e\u73b0\u57fa\u4e8e\u529b\u7684\u67d4\u987a\u63a7\u5236\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def impedance_control(target_pose, current_pose, current_vel, \n                     stiffness=1000, damping=50):\n    """\u963b\u6297\u63a7\u5236\u5668"""\n    # \u4f4d\u7f6e\u8bef\u5dee\n    pos_error = target_pose[:3] - current_pose[:3]\n    \n    # \u65b9\u5411\u8bef\u5dee (\u7b80\u5316\u4e3a\u89d2\u5ea6\u8bef\u5dee)\n    orient_error = orientation_error(target_pose[3:], current_pose[3:])\n    \n    # \u5408\u5e76\u4f4d\u7f6e\u548c\u65b9\u5411\u8bef\u5dee\n    pose_error = np.concatenate([pos_error, orient_error])\n    \n    # \u8ba1\u7b97\u671f\u671b\u529b/\u529b\u77e9\n    desired_wrench = stiffness * pose_error - damping * current_vel\n    \n    return desired_wrench\n\ndef orientation_error(target_quat, current_quat):\n    """\u8ba1\u7b97\u56db\u5143\u6570\u65b9\u5411\u8bef\u5dee"""\n    # \u8f6c\u6362\u4e3a\u65cb\u8f6c\u77e9\u9635\n    target_rot = quaternion_to_rotation_matrix(target_quat)\n    current_rot = quaternion_to_rotation_matrix(current_quat)\n    \n    # \u8bef\u5dee\u65cb\u8f6c\u77e9\u9635\n    error_rot = target_rot @ current_rot.T\n    \n    # \u8f6c\u6362\u4e3a\u8f74\u89d2\u8868\u793a\n    return rotation_matrix_to_axis_angle(error_rot)\n\n# \u4f7f\u7528\u963b\u6297\u63a7\u5236\nenv = dv.make_env("airbot_play", control_mode="pd_ee_pose")\nobs = env.reset()\n\ntarget_pose = np.array([0.5, 0.0, 0.3, 0.0, 0.0, 0.0, 1.0])\n\nfor step in range(200):\n    current_pose = obs["ee_pose"]\n    current_vel = obs["ee_vel"]  # \u5982\u679c\u53ef\u7528\n    \n    # \u8ba1\u7b97\u963b\u6297\u63a7\u5236\n    wrench = impedance_control(target_pose, current_pose, current_vel)\n    \n    # \u8fd9\u91cc\u9700\u8981\u8f6c\u6362\u4e3a\u5173\u8282\u7a7a\u95f4\u63a7\u5236\n    # \u5b9e\u9645\u5b9e\u73b0\u4e2d\u4f1a\u4f7f\u7528\u96c5\u53ef\u6bd4\u77e9\u9635\u8f6c\u6362\n    \n    obs, reward, done, info = env.step(target_pose)\n    env.render()\n'})}),"\n",(0,o.jsx)(e.h3,{id:"\u529b\u63a7\u5236",children:"\u529b\u63a7\u5236"}),"\n",(0,o.jsx)(e.p,{children:"\u5b9e\u73b0\u57fa\u4e8e\u529b\u53cd\u9988\u7684\u63a7\u5236\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def force_control(target_force, current_force, dt=0.02):\n    """\u7b80\u5355\u7684\u529b\u63a7\u5236\u5668"""\n    force_error = target_force - current_force\n    \n    # PID\u63a7\u5236\n    kp, ki, kd = 0.1, 0.01, 0.05\n    \n    # \u8fd9\u91cc\u5e94\u8be5\u7ef4\u62a4\u79ef\u5206\u548c\u5fae\u5206\u9879\u7684\u5386\u53f2\n    integral_term = 0  # \u9700\u8981\u7d2f\u79ef\n    derivative_term = 0  # \u9700\u8981\u8ba1\u7b97\u53d8\u5316\u7387\n    \n    control_output = (kp * force_error + \n                     ki * integral_term + \n                     kd * derivative_term)\n    \n    return control_output\n\n# \u5728\u6709\u529b\u4f20\u611f\u5668\u7684\u73af\u5883\u4e2d\u4f7f\u7528\nenv = dv.make_env("airbot_play_force_sensor")\nobs = env.reset()\n\ntarget_force = np.array([0, 0, -10])  # \u5411\u4e0b10N\u7684\u529b\n\nfor step in range(100):\n    if "force_sensor" in obs:\n        current_force = obs["force_sensor"]\n        force_cmd = force_control(target_force, current_force)\n        \n        # \u5c06\u529b\u6307\u4ee4\u8f6c\u6362\u4e3a\u4f4d\u7f6e\u6307\u4ee4\n        # \u5b9e\u9645\u5b9e\u73b0\u9700\u8981\u66f4\u590d\u6742\u7684\u8f6c\u6362\n        \n    obs, reward, done, info = env.step(action)\n    env.render()\n'})}),"\n",(0,o.jsx)(e.h2,{id:"-\u63a7\u5236\u5faa\u73af\u4f18\u5316",children:"\ud83d\udd04 \u63a7\u5236\u5faa\u73af\u4f18\u5316"}),"\n",(0,o.jsx)(e.h3,{id:"pid\u53c2\u6570\u8c03\u4f18",children:"PID\u53c2\u6570\u8c03\u4f18"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'class PIDController:\n    def __init__(self, kp, ki, kd, dt=0.02):\n        self.kp, self.ki, self.kd = kp, ki, kd\n        self.dt = dt\n        self.integral = 0\n        self.previous_error = 0\n    \n    def update(self, error):\n        # \u6bd4\u4f8b\u9879\n        proportional = self.kp * error\n        \n        # \u79ef\u5206\u9879\n        self.integral += error * self.dt\n        integral = self.ki * self.integral\n        \n        # \u5fae\u5206\u9879\n        derivative = self.kd * (error - self.previous_error) / self.dt\n        self.previous_error = error\n        \n        # PID\u8f93\u51fa\n        output = proportional + integral + derivative\n        return output\n    \n    def reset(self):\n        self.integral = 0\n        self.previous_error = 0\n\n# \u4e3a\u6bcf\u4e2a\u5173\u8282\u521b\u5efaPID\u63a7\u5236\u5668\njoint_controllers = [\n    PIDController(kp=100, ki=1, kd=10) for _ in range(7)\n]\n\nenv = dv.make_env("airbot_play", control_mode="pd_joint_vel")\nobs = env.reset()\n\ntarget_positions = np.array([0.0, -0.5, 0.0, 1.57, 0.0, 1.0, 0.0])\n\nfor step in range(200):\n    current_positions = obs["qpos"]\n    joint_velocities = []\n    \n    for i, controller in enumerate(joint_controllers):\n        error = target_positions[i] - current_positions[i]\n        velocity = controller.update(error)\n        joint_velocities.append(velocity)\n    \n    obs, reward, done, info = env.step(np.array(joint_velocities))\n    env.render()\n'})}),"\n",(0,o.jsx)(e.h3,{id:"\u5b89\u5168\u9650\u5236",children:"\u5b89\u5168\u9650\u5236"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'class SafetyWrapper:\n    def __init__(self, env, joint_limits, velocity_limits, acceleration_limits):\n        self.env = env\n        self.joint_limits = joint_limits  # [(min, max), ...]\n        self.velocity_limits = velocity_limits\n        self.acceleration_limits = acceleration_limits\n        self.previous_action = None\n        self.previous_time = None\n    \n    def step(self, action):\n        # \u5173\u8282\u4f4d\u7f6e\u9650\u5236\n        for i, (min_pos, max_pos) in enumerate(self.joint_limits):\n            action[i] = np.clip(action[i], min_pos, max_pos)\n        \n        # \u901f\u5ea6\u9650\u5236\n        if self.previous_action is not None:\n            dt = 0.02  # \u5047\u8bbe20ms\u63a7\u5236\u5468\u671f\n            velocity = (action - self.previous_action) / dt\n            \n            for i, max_vel in enumerate(self.velocity_limits):\n                if abs(velocity[i]) > max_vel:\n                    # \u9650\u5236\u901f\u5ea6\n                    sign = np.sign(velocity[i])\n                    action[i] = self.previous_action[i] + sign * max_vel * dt\n        \n        self.previous_action = action.copy()\n        return self.env.step(action)\n    \n    def reset(self):\n        self.previous_action = None\n        return self.env.reset()\n\n# \u4f7f\u7528\u5b89\u5168\u5305\u88c5\u5668\nbase_env = dv.make_env("airbot_play", control_mode="pd_joint_pos")\nsafe_env = SafetyWrapper(\n    base_env,\n    joint_limits=[(-3.14, 3.14)] * 7,  # \u5173\u8282\u89d2\u5ea6\u9650\u5236\n    velocity_limits=[2.0] * 7,         # \u901f\u5ea6\u9650\u5236 (rad/s)\n    acceleration_limits=[10.0] * 7     # \u52a0\u901f\u5ea6\u9650\u5236 (rad/s\xb2)\n)\n'})}),"\n",(0,o.jsx)(e.h2,{id:"-\u63a7\u5236\u6027\u80fd\u8bc4\u4f30",children:"\ud83d\udcca \u63a7\u5236\u6027\u80fd\u8bc4\u4f30"}),"\n",(0,o.jsx)(e.h3,{id:"\u8f68\u8ff9\u8ddf\u8e2a\u7cbe\u5ea6",children:"\u8f68\u8ff9\u8ddf\u8e2a\u7cbe\u5ea6"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def evaluate_tracking_performance(target_trajectory, actual_trajectory):\n    """\u8bc4\u4f30\u8f68\u8ff9\u8ddf\u8e2a\u6027\u80fd"""\n    # \u4f4d\u7f6e\u8bef\u5dee\n    position_errors = np.linalg.norm(\n        target_trajectory - actual_trajectory, axis=1\n    )\n    \n    # \u7edf\u8ba1\u6307\u6807\n    mae = np.mean(position_errors)  # \u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\n    rmse = np.sqrt(np.mean(position_errors**2))  # \u5747\u65b9\u6839\u8bef\u5dee\n    max_error = np.max(position_errors)  # \u6700\u5927\u8bef\u5dee\n    \n    return {\n        \'MAE\': mae,\n        \'RMSE\': rmse,\n        \'Max Error\': max_error,\n        \'Error Std\': np.std(position_errors)\n    }\n\n# \u6027\u80fd\u6d4b\u8bd5\ntarget_traj = plan_joint_trajectory(start, goal, duration=3.0)\nactual_traj = []\n\nenv = dv.make_env("airbot_play", control_mode="pd_joint_pos")\nobs = env.reset()\n\nfor waypoint in target_traj:\n    obs, reward, done, info = env.step(waypoint)\n    actual_traj.append(obs["qpos"])\n\nactual_traj = np.array(actual_traj)\nperformance = evaluate_tracking_performance(target_traj, actual_traj)\n\nprint("\u8f68\u8ff9\u8ddf\u8e2a\u6027\u80fd:")\nfor metric, value in performance.items():\n    print(f"  {metric}: {value:.4f}")\n'})}),"\n",(0,o.jsx)(e.h2,{id:"-\u5b9e\u9645\u5e94\u7528\u793a\u4f8b",children:"\ud83c\udfaf \u5b9e\u9645\u5e94\u7528\u793a\u4f8b"}),"\n",(0,o.jsx)(e.h3,{id:"\u62fe\u53d6\u7269\u4f53\u4efb\u52a1",children:"\u62fe\u53d6\u7269\u4f53\u4efb\u52a1"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def pick_object_demo():\n    """\u6f14\u793a\u62fe\u53d6\u7269\u4f53\u7684\u5b8c\u6574\u63a7\u5236\u6d41\u7a0b"""\n    env = dv.make_env("airbot_play_pick_task", control_mode="pd_ee_pose")\n    obs = env.reset()\n    \n    # 1. \u79fb\u52a8\u5230\u7269\u4f53\u4e0a\u65b9\n    object_pos = obs["object_pose"][:3]\n    pre_grasp_pose = object_pos + [0, 0, 0.1]  # \u4e0a\u65b910cm\n    pre_grasp_pose = np.concatenate([pre_grasp_pose, [0, 0, 0, 1]])\n    \n    print("\u79fb\u52a8\u5230\u9884\u6293\u53d6\u4f4d\u7f6e...")\n    for _ in range(50):\n        obs, reward, done, info = env.step(pre_grasp_pose)\n        env.render()\n    \n    # 2. \u4e0b\u964d\u5230\u6293\u53d6\u4f4d\u7f6e\n    grasp_pose = object_pos + [0, 0, 0.02]  # \u7565\u9ad8\u4e8e\u7269\u4f53\n    grasp_pose = np.concatenate([grasp_pose, [0, 0, 0, 1]])\n    \n    print("\u4e0b\u964d\u5230\u6293\u53d6\u4f4d\u7f6e...")\n    for _ in range(30):\n        obs, reward, done, info = env.step(grasp_pose)\n        env.render()\n    \n    # 3. \u95ed\u5408\u5939\u722a\n    print("\u95ed\u5408\u5939\u722a...")\n    # \u8fd9\u91cc\u9700\u8981\u5939\u722a\u63a7\u5236\u63a5\u53e3\n    \n    # 4. \u63d0\u5347\u7269\u4f53\n    lift_pose = grasp_pose.copy()\n    lift_pose[2] += 0.2  # \u63d0\u534720cm\n    \n    print("\u63d0\u5347\u7269\u4f53...")\n    for _ in range(50):\n        obs, reward, done, info = env.step(lift_pose)\n        env.render()\n    \n    print("\u62fe\u53d6\u4efb\u52a1\u5b8c\u6210!")\n\n# \u8fd0\u884c\u6f14\u793a\npick_object_demo()\n'})}),"\n",(0,o.jsx)(e.h2,{id:"-\u4e0b\u4e00\u6b65",children:"\ud83c\udfaf \u4e0b\u4e00\u6b65"}),"\n",(0,o.jsx)(e.p,{children:"\u73b0\u5728\u60a8\u5df2\u7ecf\u638c\u63e1\u4e86\u673a\u5668\u4eba\u63a7\u5236\u7684\u57fa\u7840\uff0c\u63a5\u4e0b\u6765\u53ef\u4ee5\u5b66\u4e60\uff1a"}),"\n",(0,o.jsxs)(e.p,{children:["\ud83d\udc49 ",(0,o.jsx)(e.a,{href:"/docs/tutorials/sensors/overview",children:"\u4f20\u611f\u5668\u914d\u7f6e"})]}),"\n",(0,o.jsx)(e.p,{children:"\u6216\u8005\u63a2\u7d22\u66f4\u9ad8\u7ea7\u7684\u4e3b\u9898\uff1a"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:(0,o.jsx)(e.a,{href:"/docs/tutorials/imitation-learning/overview",children:"\u6a21\u4eff\u5b66\u4e60"})}),"\n",(0,o.jsx)(e.li,{children:(0,o.jsx)(e.a,{href:"/docs/tutorials/reinforcement-learning/overview",children:"\u5f3a\u5316\u5b66\u4e60"})}),"\n",(0,o.jsx)(e.li,{children:(0,o.jsx)(e.a,{href:"/docs/advanced/real2sim/overview",children:"Real2Sim\u7ba1\u9053"})}),"\n"]})]})}function d(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(c,{...n})}):c(n)}}}]);