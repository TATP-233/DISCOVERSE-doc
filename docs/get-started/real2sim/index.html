<!doctype html>
<html lang="en-US" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-get-started/real2sim" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Real2Sim Asset Generation | DISCOVERSE</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://air-discoverse.github.io/img/discoverse-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://air-discoverse.github.io/img/discoverse-social-card.jpg"><meta data-rh="true" property="og:url" content="https://air-discoverse.github.io/docs/get-started/real2sim"><meta data-rh="true" property="og:locale" content="en_US"><meta data-rh="true" property="og:locale:alternate" content="zh_CN"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Real2Sim Asset Generation | DISCOVERSE"><meta data-rh="true" name="description" content="DISCOVERSE integrates real-world acquired data, 3D AIGC, and existing 3D assets (including formats such as 3DGS (.ply), meshes (.obj/.stl), and MJCF physics models (.xml)) in a unified manner, supporting their use as interactive scene nodes (objects and robots) or background nodes (scenes). We adopt 3DGS as the unified visual representation and integrate laser scanning, state-of-the-art generative models, and physics-based relighting to enhance the geometric and appearance fidelity of reconstructed radiance fields."><meta data-rh="true" property="og:description" content="DISCOVERSE integrates real-world acquired data, 3D AIGC, and existing 3D assets (including formats such as 3DGS (.ply), meshes (.obj/.stl), and MJCF physics models (.xml)) in a unified manner, supporting their use as interactive scene nodes (objects and robots) or background nodes (scenes). We adopt 3DGS as the unified visual representation and integrate laser scanning, state-of-the-art generative models, and physics-based relighting to enhance the geometric and appearance fidelity of reconstructed radiance fields."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://air-discoverse.github.io/docs/get-started/real2sim"><link data-rh="true" rel="alternate" href="https://air-discoverse.github.io/zh-Hans/docs/get-started/real2sim" hreflang="zh-CN"><link data-rh="true" rel="alternate" href="https://air-discoverse.github.io/docs/get-started/real2sim" hreflang="en-US"><link data-rh="true" rel="alternate" href="https://air-discoverse.github.io/docs/get-started/real2sim" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Real2Sim Asset Generation","item":"https://air-discoverse.github.io/docs/get-started/real2sim"}]}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="DISCOVERSE RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="DISCOVERSE Atom Feed"><link rel="stylesheet" href="/assets/css/styles.26b263b9.css">
<script src="/assets/js/runtime~main.1c80b375.js" defer="defer"></script>
<script src="/assets/js/main.25594934.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="dark";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="DISCOVERSE Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="DISCOVERSE Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">DISCOVERSE</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/get-started/installation">Docs</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/zh-Hans/docs/get-started/real2sim" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-CN">简体中文</a></li><li><a href="/docs/get-started/real2sim" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en-US">English</a></li></ul></div><a href="https://github.com/TATP-233/DISCOVERSE" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/get-started/installation">Get Started</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/get-started/installation">Installation Guide</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/get-started/quick-start">Quick Start</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/get-started/basic-concepts">Basic Concepts</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/get-started/real2sim">Real2Sim Asset Generation</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/tutorials/basic-simulation/overview">Tutorials</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Get Started</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Real2Sim Asset Generation</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Real2Sim Asset Generation</h1></header>
<p>DISCOVERSE integrates real-world acquired data, 3D AIGC, and existing 3D assets (including formats such as 3DGS (.ply), meshes (.obj/.stl), and MJCF physics models (.xml)) in a unified manner, supporting their use as interactive scene nodes (objects and robots) or background nodes (scenes). We adopt <a href="https://github.com/graphdeco-inria/gaussian-splatting" target="_blank" rel="noopener noreferrer">3DGS</a> as the unified visual representation and integrate laser scanning, state-of-the-art generative models, and physics-based relighting to enhance the geometric and appearance fidelity of reconstructed radiance fields.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="installation-instructions">Installation Instructions<a href="#installation-instructions" class="hash-link" aria-label="Direct link to Installation Instructions" title="Direct link to Installation Instructions">​</a></h2>
<p>This project has been tested on Ubuntu 18.04+.</p>
<p><strong>Setting up the Python environment for DiffusionLight (Step 3) and Mesh2GS (Step 5):</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">conda create </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">-n</span><span class="token plain"> mesh2gs </span><span class="token assign-left variable" style="color:rgb(189, 147, 249);font-style:italic">python</span><span class="token operator">=</span><span class="token number">3.10</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">conda activate mesh2gs</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip </span><span class="token function" style="color:rgb(80, 250, 123)">install</span><span class="token plain"> torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 </span><span class="token comment" style="color:rgb(98, 114, 164)"># replace your cuda version</span><br></span></code></pre></div></div>
<p>Please manually install other dependencies described in <code>requirements.txt</code>.</p>
<p><strong>To set up the Python environment for TRELLIS (Step 1)</strong>, we recommend following the <a href="https://github.com/microsoft/TRELLIS" target="_blank" rel="noopener noreferrer">official guide</a> to create a <em>new</em>, <em>separate</em> environment to avoid conflicts.</p>
<p><strong>Additionally, please install <a href="https://www.blender.org/" target="_blank" rel="noopener noreferrer">Blender</a> (recommended version: 3.1.2) for Step 4.</strong> We strongly recommend running the related scripts (<code>blender_renderer/glb_render.py</code> and <code>blender_renderer/obj_render.py</code>) in the <code>Scripting</code> panel of the Blender executable. We do <em>not</em> recommend using the <a href="https://docs.blender.org/api/current/info_advanced_blender_as_bpy.html" target="_blank" rel="noopener noreferrer">Blender Python API (bpy)</a> due to potential version mismatch issues.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="step-1-image-to-3d-generation-using-trellis">Step 1: Image-to-3D Generation using <a href="https://github.com/microsoft/TRELLIS" target="_blank" rel="noopener noreferrer">TRELLIS</a><a href="#step-1-image-to-3d-generation-using-trellis" class="hash-link" aria-label="Direct link to step-1-image-to-3d-generation-using-trellis" title="Direct link to step-1-image-to-3d-generation-using-trellis">​</a></h2>
<p><em>Generate high-quality textured meshes from a single RGB image for use as object-level interactive scene nodes.</em></p>
<p><strong>First, capture an RGB image of the target object.</strong> The object should be centered in the image and should not be too small (covering more than 50% of pixels). Note that the object does <em>not need</em> to be photographed in the simulation scene; we just need to keep the background as <em>clean</em> as possible (for instance segmentation) and ensure the ambient lighting is white, uniform, and bright.</p>
<p><strong>Then, use state-of-the-art image-to-3D generation methods to reconstruct textured meshes from the captured RGB images.</strong></p>
<ul>
<li>
<p><a href="https://github.com/microsoft/TRELLIS" target="_blank" rel="noopener noreferrer">TRELLIS</a> is the latest, open-source, state-of-the-art 3D generative model that can generate high-quality textured meshes, 3DGS, or radiance fields. We recommend setting up a new environment for TRELLIS and following the <a href="https://github.com/microsoft/TRELLIS" target="_blank" rel="noopener noreferrer">official guide</a> to run the image-to-3D generation pipeline. It&#x27;s recommended to save textured meshes in <code>.glb</code> format for compatibility with subsequent lighting estimation, Blender relighting, and Mesh2GS steps. <strong>Note: For quick setup, if you do <em>not need</em> to align object appearance with the background, you can directly generate 3DGS (<code>.ply</code>) assets for DISCOVERSE and skip steps 3~5.</strong></p>
</li>
<li>
<p>For higher quality 3D generation results, we recommend using commercial software such as <a href="https://hyper3d.ai/" target="_blank" rel="noopener noreferrer">Deemos Rodin</a> (<a href="https://arxiv.org/abs/2406.13897" target="_blank" rel="noopener noreferrer">CLAY</a>), <a href="https://www.meshy.ai/" target="_blank" rel="noopener noreferrer">Meshy</a>, <a href="https://www.tripo3d.ai/" target="_blank" rel="noopener noreferrer">TRIPO</a>, etc. They all offer free trials.</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="step-2-3d-scene-reconstruction">Step 2: 3D Scene Reconstruction<a href="#step-2-3d-scene-reconstruction" class="hash-link" aria-label="Direct link to Step 2: 3D Scene Reconstruction" title="Direct link to Step 2: 3D Scene Reconstruction">​</a></h2>
<p><em>Reconstruct background nodes as 3DGS scenes using scanners or multi-view RGB images.</em></p>
<p>We recommend using the <a href="https://www.xgrids.cn/lixelk1" target="_blank" rel="noopener noreferrer">LixelKity K1 scanner</a> and <a href="https://www.xgrids.cn/lcc" target="_blank" rel="noopener noreferrer">Lixel CyberColor</a> to generate high-quality 3DGS scenes for use as background nodes. Without a scanner, you can also use the <a href="https://github.com/graphdeco-inria/gaussian-splatting" target="_blank" rel="noopener noreferrer">original 3DGS</a> for scene reconstruction.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="step-3-lighting-estimation-using-diffusionlight">Step 3: Lighting Estimation using <a href="https://github.com/DiffusionLight/DiffusionLight" target="_blank" rel="noopener noreferrer">DiffusionLight</a><a href="#step-3-lighting-estimation-using-diffusionlight" class="hash-link" aria-label="Direct link to step-3-lighting-estimation-using-diffusionlight" title="Direct link to step-3-lighting-estimation-using-diffusionlight">​</a></h2>
<p><em>Estimate HDR environment lighting maps from a single RGB image to prepare for Step 4 (aligning object appearance with background nodes).</em></p>
<p><strong>Note:</strong> If you do <em>not need</em> to align object appearance with the background, you can directly download any <code>.exr</code> format HDR environment map from <a href="https://polyhaven.com/hdris" target="_blank" rel="noopener noreferrer">PolyHeaven</a>, skip the following process, and proceed directly to Step 4.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pre-trained-weights-for-huggingface-models">Pre-trained Weights for Huggingface Models<a href="#pre-trained-weights-for-huggingface-models" class="hash-link" aria-label="Direct link to Pre-trained Weights for Huggingface Models" title="Direct link to Pre-trained Weights for Huggingface Models">​</a></h3>
<p><strong>First, prepare input images.</strong> Capture an RGB image for each target background and resize the image to <strong>1024x1024</strong>. For this, we recommend <em>cropping</em> the image to include as much background information as possible. Alternatively, you can achieve this dimension by <em>padding black borders</em> around the image.</p>
<p>Place all processed images in a folder and set the absolute path of that folder as <code>YourInputPath</code>, while specifying <code>YourOutputPath</code> as the folder to save results. Then run the following commands:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token builtin class-name" style="color:rgb(189, 147, 249)">cd</span><span class="token plain"> DiffusionLight</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">python inpaint.py </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--dataset</span><span class="token plain"> YourInputPath </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--output_dir</span><span class="token plain"> YourOutputPath</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">python ball2envmap.py </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--ball_dir</span><span class="token plain"> YourOutputPath/square </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--envmap_dir</span><span class="token plain"> YourOutputPath/envmap</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">python exposure2hdr.py </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--input_dir</span><span class="token plain"> YourOutputPath/envmap </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--output_dir</span><span class="token plain"> YourOutputPath/hdr</span><br></span></code></pre></div></div>
<p>The final <code>.exr</code> results (saved in <code>YourOutputPath/hdr/</code>) will be used for subsequent Blender PBR rendering.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="step-4-physics-based-relighting-using-blender">Step 4: Physics-Based Relighting using Blender<a href="#step-4-physics-based-relighting-using-blender" class="hash-link" aria-label="Direct link to Step 4: Physics-Based Relighting using Blender" title="Direct link to Step 4: Physics-Based Relighting using Blender">​</a></h2>
<p><em>Render target object meshes into multi-view images by uniformly sampling cameras on a sphere and using Blender (bpy) combined with custom HDR environment maps (simulating distant lighting effects) for (pre-)physics-based relighting, for use in 3DGS optimization.</em></p>
<p>Please note that this is <em>not</em> true PBR functionality; it simply bakes lighting effects into the SH appearance of 3DGS to simulate the color tone of background scenes.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="prepare-exr-hdr-environment-maps">Prepare <code>.exr</code> HDR Environment Maps<a href="#prepare-exr-hdr-environment-maps" class="hash-link" aria-label="Direct link to prepare-exr-hdr-environment-maps" title="Direct link to prepare-exr-hdr-environment-maps">​</a></h3>
<p>Organize all HDR images to be used for (pre-)PBR into one folder, for example:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">YourHDRPath                          </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── hdr_name_0.exr</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── hdr_name_1.exr</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── hdr_name_2.exr</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">└── hdr_name_n.exr</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="render-3d-mesh-assets">Render 3D Mesh Assets<a href="#render-3d-mesh-assets" class="hash-link" aria-label="Direct link to Render 3D Mesh Assets" title="Direct link to Render 3D Mesh Assets">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="for-glb-assets-eg-objaverse--rodin-assets">For <code>.glb</code> Assets (e.g., Objaverse / Rodin Assets)<a href="#for-glb-assets-eg-objaverse--rodin-assets" class="hash-link" aria-label="Direct link to for-glb-assets-eg-objaverse--rodin-assets" title="Direct link to for-glb-assets-eg-objaverse--rodin-assets">​</a></h4>
<p>We strongly recommend using 3D mesh assets in <code>.glb</code> format similar to <a href="https://github.com/allenai/objaverse-xl" target="_blank" rel="noopener noreferrer">objaverse</a>. All <code>.glb</code> assets to be converted should be placed in the same folder, for example:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">YourInputPath                          </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── model_or_part_name_0.glb</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── model_or_part_name_1.glb</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── model_or_part_name_2.glb</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">└── model_or_part_name_n.glb</span><br></span></code></pre></div></div>
<p>Then, paste and run the <code>blender_renderer/glb_render.py</code> script in the <strong><code>Scripting</code> panel of the Blender executable</strong> with the following parameters:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--root_in_path</span><span class="token plain"> YourInputPath </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--root_hdr_path</span><span class="token plain"> YourHDRPath </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--root_out_path</span><span class="token plain"> YourOutputPath</span><br></span></code></pre></div></div>
<p>The rendering results will be saved in <code>YourOutputPath</code>, where each folder (named <code>{hdr_name_i}_{model_or_part_name_i}</code>) corresponds to the rendering results of a 3D model under certain lighting conditions, containing RGB images, depth maps, camera parameters, and <code>.obj</code> geometry files of that model.</p>
<p>If the rendering quality is unsatisfactory, you can optimize by adjusting the following parameters:</p>
<ul>
<li><code>lit_strength</code>: Environment lighting intensity; higher values result in brighter rendering.</li>
<li><code>lens</code>: Camera focal length. If the object is too small in the rendering (too many pixels are wasted in the image), try increasing this value. Conversely, if only part of the object is shown in the rendering, try decreasing this value.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="for-obj-assets-eg-robot-models">For <code>.obj</code> Assets (e.g., Robot Models)<a href="#for-obj-assets-eg-robot-models" class="hash-link" aria-label="Direct link to for-obj-assets-eg-robot-models" title="Direct link to for-obj-assets-eg-robot-models">​</a></h4>
<p>If you&#x27;re working with <code>.obj</code> format assets, such as robot models, each model typically contains multiple textures and material maps. It&#x27;s recommended to organize each model&#x27;s data into separate folders as follows:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">YourInputPath                          </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── model_or_part_name_0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">│   └── ...                </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── model_or_part_name_1            </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">│   ├── obj_name_1.obj       </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">│   ├── mtl_name_1.mtl       </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">│   ├── tex_name_1.png       </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">│   └── ...                </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── model_or_part_name_2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">└── model_or_part_name_n</span><br></span></code></pre></div></div>
<p>Robot models developed by DISCOVER LAB, including MMK2, AirBot, DJI, RM2, etc., can be obtained through this <a href="https://pan.baidu.com/s/1BW0GoDFmd0mPz9QItuJs7A" target="_blank" rel="noopener noreferrer">link</a> (extraction code: 94po).</p>
<p>Then, paste and run the <code>blender_renderer/obj_render.py</code> script in the <strong><code>Scripting</code> panel of the Blender executable</strong> with the following parameters:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--root_in_path</span><span class="token plain"> YourInputPath </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--root_hdr_path</span><span class="token plain"> YourHDRPath </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--root_out_path</span><span class="token plain"> YourOutputPath</span><br></span></code></pre></div></div>
<p>This script uses the same parameters as <code>blender_renderer/glb_render.py</code>.</p>
<p>Convert the camera parameters generated by Blender rendering to the format required by COLMAP by running:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token builtin class-name" style="color:rgb(189, 147, 249)">cd</span><span class="token plain"> blender_renderer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">python models2colmap.py </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--root_path</span><span class="token plain"> YourOutputPath</span><br></span></code></pre></div></div>
<p>Ensure that when running <code>obj_render.py</code> / <code>glb_render.py</code> and <code>models2colmap.py</code>, the <strong>camera intrinsics (i.e., <code>--resolution</code>, <code>--lens</code>, <code>--sensor_size</code>) remain strictly consistent</strong>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="step-5-mesh2gs">Step 5: Mesh2GS<a href="#step-5-mesh2gs" class="hash-link" aria-label="Direct link to Step 5: Mesh2GS" title="Direct link to Step 5: Mesh2GS">​</a></h2>
<p><em>Convert textured meshes to 3DGS.</em></p>
<p>Run Mesh2GS for each 3D asset individually:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token builtin class-name" style="color:rgb(189, 147, 249)">cd</span><span class="token plain"> LitMesh2GS</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">python train.py </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">-s</span><span class="token plain"> YourOutputPath/model_or_part_name_i </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">-m</span><span class="token plain"> YourOutputPath/model_or_part_name_i/mesh2gs </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--data_device</span><span class="token plain"> cuda </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--densify_grad_threshold</span><span class="token plain"> </span><span class="token number">0.0002</span><span class="token plain"> </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">-r</span><span class="token plain"> </span><span class="token number">1</span><br></span></code></pre></div></div>
<p>The 3DGS results converted from each 3D asset will be saved in a new folder <code>mesh2gs</code> under <code>YourOutputPath/model_or_part_name_i</code>.</p>
<p>Since 3DGS is inherently memory-inefficient, we recommend roughly controlling the number of generated 3DGS points by specifying <code>--densification_interval</code>. The larger this value, the sparser the generated 3DGS scene and the less memory required.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/TATP-233/DISCOVERSE/tree/main/discoverse-docs/docs/get-started/real2sim.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/get-started/basic-concepts"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Basic Concepts</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/tutorials/basic-simulation/overview"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Basic Simulation Overview</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#installation-instructions" class="table-of-contents__link toc-highlight">Installation Instructions</a></li><li><a href="#step-1-image-to-3d-generation-using-trellis" class="table-of-contents__link toc-highlight">Step 1: Image-to-3D Generation using TRELLIS</a></li><li><a href="#step-2-3d-scene-reconstruction" class="table-of-contents__link toc-highlight">Step 2: 3D Scene Reconstruction</a></li><li><a href="#step-3-lighting-estimation-using-diffusionlight" class="table-of-contents__link toc-highlight">Step 3: Lighting Estimation using DiffusionLight</a><ul><li><a href="#pre-trained-weights-for-huggingface-models" class="table-of-contents__link toc-highlight">Pre-trained Weights for Huggingface Models</a></li></ul></li><li><a href="#step-4-physics-based-relighting-using-blender" class="table-of-contents__link toc-highlight">Step 4: Physics-Based Relighting using Blender</a><ul><li><a href="#prepare-exr-hdr-environment-maps" class="table-of-contents__link toc-highlight">Prepare <code>.exr</code> HDR Environment Maps</a></li><li><a href="#render-3d-mesh-assets" class="table-of-contents__link toc-highlight">Render 3D Mesh Assets</a></li></ul></li><li><a href="#step-5-mesh2gs" class="table-of-contents__link toc-highlight">Step 5: Mesh2GS</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Documentation</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/get-started/installation">Get Started</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/get-started/basic-concepts">Basic Concepts</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/tutorials/basic-simulation/overview">Tutorials</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/TATP-233/DISCOVERSE/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Discussions<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/TATP-233/DISCOVERSE/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item">Issues<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/TATP-233/DISCOVERSE" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Resources</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://air-discoverse.github.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Paper<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/TATP-233/DISCOVERSE" target="_blank" rel="noopener noreferrer" class="footer__link-item">Main Repository<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/TATP-233/DISCOVERSE/releases" target="_blank" rel="noopener noreferrer" class="footer__link-item">Changelog<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 DISCOVERSE Team. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>